---
title: "Mixture-of-Experts Models for Claim Frequency and Severity"
subtitle: "CAS RPM, March 15, 2023, San Diego CA"
author:
    - name: "Ian Weng (Sophia) Chan"
      affiliation: "PhD Candidate, University of Toronto"
bibliography: references.bib
format:
  revealjs: 
    theme: white
    toc: true
    toc-depth: 1
    slide-level: 2
    slide-number: true
    margin: 0.1
    center: false
    fig-cap-location: "bottom"
    fig-align: "center"
    chalkboard: 
      buttons: false
    preview-links: auto
    # logo: images/quarto.png
    css: styles.css
    # footer: "CAS RPM, Mar 15 2023, San Diego CA"
# resources:
#   - demo.pdf
---

## Overview

::: incremental
- We propose a flexible Mixture-of-Experts (MoE) framework for modelling claim frequency and severity, and for many other applications

- We showcase a few case studies to demonstrate the theoretical flexibility and wide applicability of the framework

- Our model has been implemented in Julia and R as open-source packages, readily available for a variety of applications

- Joint work by the [actuarial research group](https://actsci.utstat.utoronto.ca/) at the University of Toronto: \ \ \ \  Tsz Chai (Samson) Fung, Spark Tseung, Prof. Andrei Badescu, and Prof. X. Sheldon Lin
:::

# Motivating Examples

## Actuaries: GLM is great!

::: {.columns}
::: {.column width="60%"}
::: incremental
- GLM is simple yet powerful.

- GLM is easy to implement.

- GLM is interpretable and accessible.

- **However, GLM can fail miserably in insurance applications, because real data do not satisfy GLM assumptions.**
:::
:::

::: {.column width="5%"}
:::

::: {.column width="35%"}
![](plots/glm-book.jpg){width=400 fig-align="left"}
:::

:::

---

## GLM fails when...

::: nonincremental
- Claim frequency distribution is heavy-tailed.

- There is an excess probability of zero claims.
::: 

. . .

Example: Australian auto insurance data (*ausprivauto040*) in *CASDatasets* [@dutang2020package],
analyzed in [@badescu2021actuaryarticle].

![](plots/AUS-hist-log-frequency-ex-MoE.png){width=500 fig-align="center"}

---

## GLM fails when...

::: nonincremental
- Claim severity distribution is multimodal and/or heavy-tailed.

- Observations are censored and/or truncated.
:::

. . .

::: {.columns}
::: {.column width="40%"}
Example: French auto insurance data (*freMTPLsev*) in *CASDatasets* [@dutang2020package],
analyzed in [@tseung2021lrmoe].
:::

::: {.column width="60%"}
![](plots/FRA-hist-log-claim.png){width=450 fig-align="center"}
:::
:::

---

## Insurance data are heterogeneous.

::: nonincremental
- Policyholders' risk profiles are different, even within the same portfolio.
- One way to capture such heterogeneity is to use a **mixture** model.
:::

. . .

Example: Modelling claim frequency with a 3-component Poisson mixture.

![](plots/model-structure-no-regression.png){width=800 fig-align="center"}

---

## Covariates are important.

::: nonincremental
- Policyholders' information, or covariates, are predictive of their risk profiles.
- We may use **regression** to classify policyholders into different risk groups, and model each group separately.
:::

. . .

Example: A Poisson mixture model combined with logistic regression.

![](plots/model-structure.png){width=800 fig-align="center"}

---

## MoE = Regression + Mixture

This is an example of our proposed Mixture-of-Experts (MoE) framework.

::: incremental
- We first classify policyholders into different latent risk groups with a multinomial logistic regression.
- Within each risk group, we model the response (frequency or severity) with an appropriate distribution (or expert).
:::

![](plots/model-structure.png){width=800 fig-align="center"}

---

## MoE: Flexible and Powerful

::: nonincremental
- The MoE framework is extremely flexible and powerful (more details later).
- For example, it offers a much better fit to data compared with GLM.
:::

. . .

Example: Australian auto insurance data (*ausprivauto040*) in *CASDatasets* [@dutang2020package],
analyzed in [@badescu2021actuaryarticle].

![](plots/AUS-hist-log-frequency.png){width=500 fig-align="center"}

---

## MoE: Flexible and Powerful

Example: French auto insurance data (*freMTPLsev*) in *CASDatasets* [@dutang2020package],
analyzed in [@tseung2021lrmoe].

::: {.columns}
::: {.column width="50%"}
![](plots/FRA-hist-vs-fitted.png){width=450 fig-align="center"}
:::

::: {.column width="50%"}
![](plots/FRA-qq-fitted.png){width=450 fig-align="center"}
:::
:::

# A Crash Course on (LR)MoE

## Model Setup

::: incremental
- Let $\mathbf{x}_{i} = (x_{i0}, x_{i1}, \dots, x_{iP})^{T}$ denote the $(P+1)$-dimensional covariate vector 
for policyholder $i$ \ for \ $i=1, 2, \dots, n$.

- Based on the covariates, policyholder $i$ \ is classified into one of \ $g$ \ latent risk classes by a logit **gating function**
$$
    \pi_{j}(\mathbf{x}_{i}; \mathbf{\alpha}_{j}) = \frac{\exp(\mathbf{\alpha}^{T}_{j}\mathbf{x}_{i})}{\sum_{j^{\prime}=1}^{g} \exp(\mathbf{\alpha}^{T}_{j^{\prime}}\mathbf{x}_{i}) }, \quad j = 1, 2, \dots, g,
$$
where $\mathbf{\alpha}_{j} = (\alpha_{j0}, \alpha_{j1}, \dots, \alpha_{jP})^{T}$ is a vector of regression coefficients for latent class $j$.

- Given the assignment of latent class \ $j \in \{ 1, 2, \dots, g \}$, the response variables $\mathbf{y}_{i}$ are modelled by an
**expert function** \ $f_j(\mathbf{y}_{i}; \mathbf{\varphi}_j)$ \ with parameters $\mathbf{\varphi}_j$.
:::

## Example: 3-Component MoE

![](plots/moe-model-setup.png){width=450 fig-align="center"}

## More Details
### Multinomial Logit for Classification

::: incremental
- We have assumed a multinomial logistic gating function for classification into different latent risk classes.
$$
    \pi_{j}(\mathbf{x}_{i}; \mathbf{\alpha}_{j}) = \frac{\exp(\mathbf{\alpha}^{T}_{j}\mathbf{x}_{i})}{\sum_{j^{\prime}=1}^{g} \exp(\mathbf{\alpha}^{T}_{j^{\prime}}\mathbf{x}_{i}) }, \quad j = 1, 2, \dots, g,
$$

- It is possible to pose other functions for this classification stage, e.g. a probit regression.

- The multinomial logistic regression is a good choice for its interpretability and ease of computational implementation.
:::

## More Details
### Expert Functions for the Response

::: incremental
- In the expert functions $f_j(\mathbf{y}_{i}; \mathbf{\varphi}_j)$, we have assumed some **fixed** parameters
$\mathbf{\varphi}_j$ which are **independent** of the covariates $\mathbf{x}_{i}$.

- It is possible to also incorporate the covariates $\mathbf{x}_{i}$ in the parameters of the expert functions such that
$$
    f_j(\mathbf{y}_{i}; \mathbf{\varphi}_j(\mathbf{x}_{i})) = f_j(\mathbf{y}_{i}; \mathbf{\varphi}_j(\mathbf{x}_{i}, \mathbf{\beta}_j))
$$
where $\mathbf{\beta}_j$ is a vector of regression coefficients for $j$-th expert function.

- The interpretation of our framework: the risk profiles of policyholders within the same latent group
are homogeneous and independent of their covariates.
:::

## More Details

### Dependence of Response Variables

::: incremental
- The response variables $\mathbf{y}_{i}$ may be multi-dimensional, e.g. \ $\mathbf{y}_{i} = (y_{i1}, y_{i2})$ 
for two auto insurance coverages purchased by the same policyholder.
- In this case, we assume **conditional independence** between the two dimensions of $\mathbf{y}_{i}$, given the
assignment of latent class $j$.
- However, they are in fact **dependent** due to the mixture structure, which is essential for capturing
the **correlation** between the two (or multiple) coverages observed in real insurance data.
- An example on correlated frequency will be given later.
:::

## LRMoE

::: incremental
- Our modelling framework is called the **Logit-weighted Reduced** Mixture-of-Experts (LRMoE) due to
the simplifying assumptions on the expert functions.

- It is a special case of the more general class of Mixture-of-Experts (MoE) models, see e.g. [@jordan1994hierarchical]
(figure extracted from the paper).

  ![](plots/jordan-general-moe-setup.png){width=500 fig-align="center"}
:::

## Simpler is sometimes better

### ... or at least equally good.

::: incremental
- The general modelling framework of MoE is extremely flexible and powerful.

- However, our LRMoE framework has a much **simpler** structure and 
it can be **as good as** the general MoE in terms of fitting the data.

- Formally speaking, under mild conditions [@fung2019classtheory],
  - LRMoE is **dense** in the class of MoE models.
  - LRMoE is **dense** in the class of (univariate and multivariate) frequency and severity distributions.

::: {.fragment .highlight-red}
- ***In short, LRMoE is theoretically guaranteed to be flexible and powerful.***
:::

- Indeed, actuaries may prefer simpler models (like LRMoE) in practice for their interpretability and ease of implementation.
:::


# Applications in Actuarial Modelling

## Overview

We will consider several applications of LRMoE on real insurance data.

We aim to demonstrate the following **desirable features** and **potential use cases** of our framework for actuarial modelling.

::: incremental
- Fitting both frequency and severity data with much better results

- Modelling correlated claim frequency in a single framework

- Dealing with censored/truncated data due to policy limits/deductibles

- Extending to other problems such as claims reserving, IBNR prediction, and insurance risk selection
:::

## 1. Univariate Frequency and Severity

Our introductory examples on the Australian (*ausprivauto040*) and French (*freMTPLsev*)
auto insurance datasets have already demonstrated the superior fitting performance of LRMoE 
compared to GLM.

::: nonincremental
- Australian: 3 components of Poisson
- French: 6 components of zero-inflated Lognormal
:::

**Question: What expert functions (distributions) should one use?**

::: {.columns}
::: {.column width="40%"}
![](plots/AUS-hist-log-frequency.png){width=450 fig-align="center"}
:::

::: {.column width="30%"}
![](plots/FRA-hist-vs-fitted.png){width=450 fig-align="center"}
:::

::: {.column width="30%"}
![](plots/FRA-qq-fitted.png){width=450 fig-align="center"}
:::
:::


## Theory vs Practice

::: incremental

- [@fung2019classtheory] state that, in theory, LRMoE is flexible under *mild conditions*,
e.g. suitable choices of expert functions.
  - Frequency: Conway-Maxwell-Poisson, Renewal Count, etc.
  - Severity: Lognormal, Gamma, Inverse Gaussian, etc.

- In practice, the choice of expert functions depends on the following considerations:
  - **Preliminary Analysis**: Let the dataset speak for itself.
  - **Domain Knowledge**: Models are more powerful when combined with actuaries' discretion.
  - **Trial and Error**: It never hurts to do some experimentation!
  - **Computational Constraints**: Sometimes it may be worthwhile to sacrifice some fitting performance
    for a faster workflow.

:::

## 2. Correlated Claims Frequency 

[@fung2019classapplication] considers fitting LRMoE to the frequency of two correlated claims:
Third-Party Liability (TPL) and Car Damages (CD).

::: incremental
- We consider a European major insurer's portfolio with 18K policyholders.

- Empirically, the two coverages are correlated with Kendall's $\tau$ = 0.241, so it may not be
appropriate to assume independence.

- CD coverage is over-dispersed, and both TPL and CD are right-skewed and heavy-tailed, which
renders Poisson a poor modelling choice.

- We fit (zero-inflated, ZI-) negative binomial (NB) GLM as benchmark models.

- We use the Erlang-Count (EC) experts for LRMoE, which will make our model theoretically flexible.
Five components are used based on the Bayesian Information Criterion (BIC).
:::


## Empirical vs Fitted Distributions {.smaller}

LRMoE with EC experts outperforms both NB GLM and ZINB GLM in terms of fitting the chi-square statistic and the log-likelihood.

{{< include tables/EUR-correlated-frequency-fit-table-1.md >}}

## Correlation and Higher Moments {.smaller}

The LRMoE model produces a fitted Kendall's $\tau$ = 0.240 (vs empirical value 0.241),
which indicates the dependence is well captured.

Besides, LRMoE also captures the higher-order moments of the two coverages better than
the benchmark models.

{{< include tables/EUR-correlated-frequency-moments-table-1.md >}}


## More Insights into Risk Profiles

Since LRMoE is a mixture-based model, we can gain more insights into the risk profiles of the
policyholders via the latent class probabilities.

::: incremental
- Let $Z_{ij}$ denote the indicator variable for the $i$-th policyholder belonging to the $j$-th latent risk group.

- **Prior**: unconditional on claim information $P(Z_{ij}=1|\mathbf{x}_i,\mathbf{\hat{\Phi}})=\pi_j(\mathbf{x}_i;\mathbf{\hat{\alpha}})$.

- **Posterior**: conditional on claim information $P(Z_{ij}=1|\mathbf{y}_i,\mathbf{x}_i,\mathbf{\hat{\Phi}})$,
which can be calcuated in closed-form.

- By comparing the prior against the posterior, we can gain insights into the risk profiles of the policyholders
based on their claim history in the current contract period, in addition to the fixed covariate information.
:::

## Comparing Sample Policyholders

::: nonincremental
- **Policyholder A**: Lots of undesirable risk characteristics 
<!-- (e.g. young driver, new diesel vehicle under a poor car class, claim record last year), -->
but no claims are observed during the contract period.

- **Policyholder B**: An average risk profile with 1 CD claim.

- **Policyholder C**: Relatively desirable risk characteristics 
<!-- (e.g. older driver, new petrol vehicle under a good car class), -->
but eventually had 1 TPL and 2 CD claims during the contract period.
:::

![](plots/EUR-latent-probs.png){width=450 fig-align="center"}


## 3. Application to Risk Selection

How can we utilize such additional insights based on claim history?

::: incremental
- If we **assume** the risk profile of the next contract period is the same as the current posterior,
then we can use the posterior probabilities to identify the policyholders with high risk.

- More specifically, policyholders with a high posterior probability
$P(Z_{ij}=1|\mathbf{y}_i,\mathbf{x}_i,\mathbf{\hat{\Phi}})$ in the risky groups $j$ are 
regarded as risky.

- Alternatively, we can also look at the posterior mean of the response $\mathbf{Y}_{i}$, given the
covariates $\mathbf{x}_i$ and the fitted parameters $(\mathbf{\hat{\alpha}}, \mathbf{\hat{\Phi}})$,
as well as the claim history $\mathbf{y}_i$.

:::

. . .

This assumption is quite strong and may not be statistically rigorous, compared with e.g. a random effects model
for panel data. However, we will see this approach is already quite sufficient for practical purposes.


## Selection of Risky Policyholders

In a working technical report, we apply the preceding risk selection approach to a real dataset 
from a major Canadian automobile insurer.

::: incremental

- We consider a portfolio from 2014 to 2020.

- We re-fit the LRMoE model every half year, and select the top 5% most risky policyholders based on
  - Covariates only: using heuristic rules on covariates such as driver/vehicle age, car class, etc.
  - Covariates + claim history: using the posterior predicted mean of the response.

- We compare which losses are identified and how much is saved by eliminating the losses
generated by the risky policyholders.

- We will see **LRMoE outperforms by a huge margin**!

:::

## Covariates Only

![](plots/CAN-loss-identified-rule-1.png){width=450 fig-align="center"}

## Covariates + Claim History

![](plots/CAN-loss-identified-rule-2.png){width=450 fig-align="center"}

## Comparison of Cumulative Cashflow

![](plots/CAN-cumulative.png){width=450 fig-align="center"}


## 4. Data Censoring and Truncation

Data censoring and truncation are common in insurance data, e.g. due to policy
limits and deductibles, as well as the observation times for incurred but not reported (IBNR) claims.

::: incremental

- Parameter estimation becomes more involved when data are censored and/or truncated, but
the underlying idea remains the same.

- [@fung2021fitting] first derived an algorithm for estimating the parameters of LRMoE
with censored and/or truncated data, and presented two applications: 
  - Fitting reporting delay (censored data), and
  - Ratemaking in the presense of policy deductibles (truncated data).

- [@fung2021new] presented a more comprehensive framework for applying LRMoE
to the prediction of IBNR claims with a case study on a real dataset from 
a major European automobile insurer.

:::

<!-- We will focus the latter application on the prediction of IBNR claims. -->


## 5. IBNR Prediction

[@fung2021new] considered LRMoE with Transformed Gamma (TG) experts, which is intended to 
capture the heavy-tailedness.

::: incremental
- We fit **both** the severity and claim delay time with LRMoE using TG experts.

- We assume **claim arrival** follows a non-homogeneous Poisson process, with intensity dependent on policyholder covariates.

- Once these components are fitted, we can produce a predicted **distribution** of IBNR claims for each policyholder at any valuation date.
:::

. . .

![](plots/IBNR-illustration.png){width=800 fig-align="center"}

## Heavy-Tailedness of Severity

![](plots/IBNR-severity-comparison.png){width=1000 fig-align="center"}

## Fitted Severity Distribution

![](plots/IBNR-severity-fit.png){width=1000 fig-align="center"}

## Fitted Reporting Delay Distribution

![](plots/IBNR-delay-fit.png){width=1000 fig-align="center"}

## Predicted IBNR Distribution

![](plots/IBNR-prediction.png){width=1000 fig-align="center"}


# Software Implementations

## Fitting LRMoE to Real Data

As a mixture-based model, parameter estimation for LRMoE can be done by the 
Expectation-(Conditional-)Maximization, or E(C)M, algorithm.

::: incremental
- [@fung2019classapplication] contains an illustration of fitting LRMoE to frequency data.

- [@fung2021fitting] focuses on estimation from censored and/or truncated data.

- A general introduction to the E(C)M algorithm can be found in [@mclachlan2007algorithm].
A general introduction to finite mixture models can be found in [@mclachlan2019mixture].
:::

. . .

Implementing the estimation involves some customization based on the selection of experts functions, as well as modifications based on the presence of censored and/or truncated data.

## We have already built the wheels!

Our research group has developed two software packages for LRMoE, which are **open-source** and
**readily available** for use on real datasets [@tseung2020lrmoe] and [@tseung2021lrmoe].

. . .

::: {.columns}

::: {.column width="50%"}
![](plots/Julia-logo.png){width=120 fig-align="center"}

For working with large real datasets.

```julia
# Installation
using Pkg
Pkg.add("LRMoE")

# Using the package
using LRMoE
```
:::

::: {.column width="50%"}
![](plots/R-logo.png){width=100 fig-align="center"}

For the research community.

```r
# Installation
library(devtools)
install_github("UofTActuarial/LRMoE")

# Using the package
library(LRMoE)
```
:::
:::

. . .

It is not difficult to interface with Python via packages like `PyJulia` [@takafumi_arakaki_2022_7340220] and
`rpy2` ([github repository](https://github.com/rpy2/rpy2)).


## Package Highlights

Our software packages offer several new distinctive features which are motivated by 
various actuarial applications and mostly cannot be achieved using existing packages for mixture models.

::: incremental
- A wider coverage on frequency and severity distributions and their zero-inflated variants;
- The flexibility to vary classes of distributions across components;
- Parameter estimation under data censoring and truncation;
- A collection of insurance rate making and reserving functions; and
- Model selection and visualization tools.
:::

. . .

While LRMoE(.jl) was initially developed for actuarial application, our packages also allow for 
**customized expert functions** for various modelling problems within and beyond the insurance context. 

## Live Demo!

We will see `LRMoE.jl` in action, including data simulation and model fitting to similated and 
real datasets.

- Reproducible code available on [github](https://github.com/UofTActuarial/Demo-LRMoE-jl)
- Check out the complete documentation: [Julia](https://actsci.utstat.utoronto.ca/LRMoE.jl/stable/) / [R](https://actsci.utstat.utoronto.ca/LRMoE/)


# Summary

## Summary

::: incremental

- GLM is popular with actuaries, but it may fail on complex insurance datasets.

- We introduced the **LRMoE** framework for insurance frequency and severity data, as well as many other applications.

- Our proposed model is shown to provide **superior performance** on various datasets and modelling problems.

- We have developed two software packages for LRMoE, which are **open-source** and **readily available** for use on real applications.

- Many potential extensions and applications for LRMoE are still ongoing... Keep an eye on our latest [publications
  and presentations](https://actsci.utstat.utoronto.ca/publication/)!

- Our research group is always looking for collaborations. Please [reach out to us](https://actsci.utstat.utoronto.ca/) if you have
  interesting and challenging problems to solve!

:::

# Appendix

## References

::: {#refs}
:::